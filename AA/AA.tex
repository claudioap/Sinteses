\documentclass[]{report}
\usepackage[a4paper, total={7in, 8.5in}]{geometry}
\usepackage[portuguese]{babel}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{color}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{amsmath}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\DeclareMathOperator*{\argmax}{arg\,max}

\begin{document}
\begin{titlepage}
	\centering
	\vspace{5cm}
	{\huge\bfseries Aprendizagem Automática\\
	(Machine Learning)\par}
	\vspace{1cm}
	{\scshape\Large Síntese baseada no conteúdo lecionado na\\
	 FCT/Universidade Nova de Lisboa\par}
	\vspace{2cm}
	Adaptado por:\\
	{\Large \textit{Cláudio Afonso de Sousa Pereira}\\
	(sinteses$\text{@}$claudiop$.$com)\par}
	\vspace{1cm}
	Do material lecionado por:\\
	{\Large \textit{Ludwig Krippahl}\\
	(ludi$\text{@}$fct$.$unl$.$pt)\par}
	\vspace{1cm}
	{\large \today\par}
	\vfill
	Adaptação licenciada:\\
	\href{http://creativecommons.org/licenses/by-sa/4.0/}{\includegraphics[scale=0.8]{../ccbysa.png}}
\end{titlepage}
\tableofcontents
\chapter{Introdução}
\section{O que é}
A aprendizagem automática (machine learning em inglês) é a ciência que estuda sistemas que se melhoram com dados.
Existem três elementos básicos na definição de um sistema de aprendizagem automática:
\begin{itemize}
\item A tarefa que o sistema desempenha
\item A medida de performance que avalia o sistema
\item Os dados que podem ser utilizados para melhorar o sistema
\end{itemize}
\section{Tipos de problemas}
Existem dois tipos principais de problemas a resolver.\\
Quando se querem prever valores contínuos o problema é de \textbf{regressão}.\\
Quando se querem prever categorias dentro de um conjunto discreto, o problema é de \textbf{classificação}.\\[0.2cm]
Podem querer encontrar-se regras de associação que são distribuições probabilísticas conjuntas dos elementos em análise.
Por exemplo o problema de otimizar o posicionamento dos produtos numa loja por base nos produtos que são comprados em conjunto.\\[0.2cm]
\textbf{Clustering} é o agrupamento de elementos em análise pela sua similaridade.
Por exemplo categorias de produtos, fotos de sinais de trânsito.
\section{Tipos de aprendizagem}
Aprendizagem automática é \textbf{supervisionada} se utiliza dados etiquetados (isto é, cujas caraterísticas são conhecidas) para criar hipóteses.
Por exemplo imagens de sinais de trânsito que indicam qual o sinal.\\
O processo de aprendizagem supervisionada é:[imagem]\\[0.2cm]
Para contraste é \textbf{não supervisionada} se tem de retirar conclusões a partir de dados que se desconhece o que são.
Por exemplo textos retirados da Internet.
O processo de aprendizagem não supervisionada é: [imagem]\\[0.2cm]
Há ainda mais tipos de aprendizagem, como a híbrida dita \textbf{semi-supervisionada}, ou a que decorre num contexto de tempo real dita aprendizagem por reforço em que as alterações de estado indicam os passos do problema.
\section{Utilidade}
A aprendizagem automática é útil em particular para problemas baseados em condições difíceis de definir, ou cujo contexto se pode alterar em o programa ter de ser reprogramado.\\
As sugestões dadas por um motor de busca são geradas por base nestas automações, ou o reconhecimento de matriculas. São sistemas que tem de ser flexíveis a novos dados, e simples de voltar a treinar para identificar por exemplo um novo formato de matricula, ou os contextos em que uma nova palavra é colocada.\\
Seria demasiado trabalhoso para um humano criar e adaptar sistemas estáticos para fazer esses reconhecimentos.
\section{Conceitos fundamentais}
Em aprendizagem automática quer-se otimizar a solução de um problema a partir de um espaço de resultados.\\
Se existirem duas caraterísticas diferentes (por exemplo peso e altura) nos eixos $X,Y$ e dados etiquetados como pertencentes a uma de varias \textbf{classes} (p.ex saudável ou não saudável), então a \textbf{classe de hipóteses} é o conjunto de formas possíveis para separar as classes.\\
Uma classe de hipóteses pode ser um conjunto de retas, círculos, parábolas.\\
Uma boa classe de hipóteses admite hipóteses que modelam bem os dados.\\[0.2cm]
Veja-se por exemplo o seguinte espaço:\\
.[Imagem]\\[0.2cm]
Uma classe de hipóteses pode ser dada pela equação $(x-\theta_1)^2+(y-\theta_2)^2 = 1$\\
Uma hipótese dentro dessa classe pode ser dada por $\theta=(-1,-1)$\par
A escolha de uma classe de hipóteses é enviesada uma vez que é escolhida uma que nós pensamos representar os dados, não uma que representa o universo dos dados. A esse enviesamento é dado o nome de \textbf{enviesamento indutivo} (\textit{inductive bias}).
Sem enviesamento indutivo não seria possível extrapolar nada a partir dos dados, é sempre necessário assumir alguma coisa.
Escolher a melhor classe de hipóteses é o problema chamado de \textbf{seleção de modelo}(\textit{model selection}).
Veja-se dois modelos (classes de hipóteses) representativos dos dados, ainda que com enviesamentos distintos. Um separa as classes com linhas horizontais $y=\theta$ e o outro com recurso à equação do circulo proposta acima:\\
.[imagem]\par
O $\theta$ utilizado para se obter uma hipótese a partir da classe de hipóteses é o vetor dos \textbf{parâmetros}.
\section{Aprendizagem supervisionada}
A aprendizagem supervisionada consiste em aprender a prever atributos a partir de dados com esses atributos.
O objetivo dos problemas de aprendizagem é encontrar-se a função $g(\theta,X):X\rightarrow Y$
que melhor corresponda as caraterísticas $X$ encontradas nos dados do conjunto $Y$.
$g(\theta,X)$ é uma aproximação à função desconhecida $F(X):X\rightarrow Y$ que sabe mapear qualquer $X$ (mesmo que desconhecido) para um valor de $Y$.
Como a aprendizagem é supervisionada, já se conhecem alguns relacionamentos $X\rightarrow Y$ que permitem que se determine uma boa $g(\theta,X)$.\\[0.2cm]
Por exemplo seja uma pessoa o objeto de análise, a pessoa tem altura $x_1$, peso $x_2$ e vive em $x_3$ e pretende-se saber se a pessoa é saudável ou doente ($Y \in \{\text{saudável,doente}\}$).\\[0.2cm]
Pode formular-se um problema de aprendizagem supervisionada como:
\begin{enumerate}
\item \textbf{Tarefa}: Prever $Y$ no conjunto $\{(x_1,y_2),\dots,(x_n,y_n)\}$
\item \textbf{Medida de performance}: Erro de treino em $Y$.
\item \textbf{Dados}: O conjunto $\{(x_1,y_2),\dots,(x_n,y_n)\}$.
\end{enumerate}
No entanto esta formulação não é correta porque o objetivo é prever valores que podem ser desconhecidos, mas a medida de performance é baseada nos dados de treino.
A não ser que o conjunto de treino seja imensamente grande, então existiriam erros mensuráveis entre $g$ e $F$.\par
É simples assumir que existem tais erros.
Assuma-se que $g$ é definida para coincidir sempre com os dados de treino.
Se for encontrado um par $(X,Y)$ que não esteja definido em $g$, mesmo que $g$ possa estar muito próxima se não tiver exatamente o mesmo valor então não tem erro nulo.
Intuitivamente, quanto menor for o conjunto de treino, menor a precisão de $g$.

Existem varias técnicas para minimização deste enviesamento no treino (que serão vistas adiante).
Uma prática comum é a separação do conjunto de treino em dois conjuntos distintos, um que serve para treino e outro para validação.
\chapter{Regressão}
\section{Regressão Linear}
Uma regressão linear é uma regressão em que a classe de hipóteses corresponde ao modelo $y = \theta_1 x_1 + \theta_2 x_2 + \dots + \theta_n x_n + \theta_{n+1}$, constituído apenas por parâmetros e termos lineares. [continuar]
\section{Método dos mínimos quadrados}
\section{Ajuste dos dados}
(Falar Subajuste sobreajuste)
\section{Tipos de erro}
\section{Regularização}
Prevenir que um modelo se ajuste demasiado e cause sobre-ajuste.[continuar]
\subsection{Regressão de Ridge}
$$J(\theta) \sum_{t=1}^n[y^t - g(x^t | \theta)]^2 + \sum_{j=1}^m \theta^2_j$$
\section{Enviesamento}
\chapter{Classificação}
\section{Introdução}
Uma classificação é um tipo de análise de caraterísticas. Enquanto que uma regressão ambiciona prever os valores valores de novos elementos por base nos elementos utilizados para treino, uma classificação agrupa os elementos de treino em classes disjuntas e por resultado indica em qual das classes é que um novo elemento se encontra.\\[0.2cm]
Veja-se a seguinte figura que representa a reação de células a dois genes distintos: [imagem]\\
Na figura apresentada existem duas classes (com ou sem tumor), sendo que a classificação de um nova célula entende-se por concluir se tem ou não tumor por base na reação da mesma aos genes.
\subsection{Separabilidade}
A separabilidade é uma propriedade das classes de classificação que indica se é possível serem isoladas entre si. Quando podem, à fronteira de separação dá-se o nome de \textbf{discriminante}.\\
Duas classes dizem-se linearmente separáveis se puderem ser separadas por um polinómio de primeiro grau.\\[0.5cm]
Relembre-se que em duas dimensões se pode definir uma reta com dois parâmetros ($y=mx+b$), e tal é suficiente para indicar qual classe é qual. Quando as classes são separadas por hiperplanos é igualmente necessário distinguir qual dos lados do hiperplano contem que classe, pelo que a convenção é definir um vetor $\vec w$ perpendicular ao hiperplano de separação.
$$\vec w^T \vec x + w_0 = 0$$
Para simplificar a representação e computação abrevia-se:
$$\widetilde{w} = (w_0, \vec w),\quad \widetilde x = (1, \vec x),\quad y(\vec x) = \widetilde w^T \widetilde x$$
\subsection{Normalização}
$$x_{new} = \frac{x-min(X)}{max(x)-min(X)}$$
\subsection{Estandardização}
$$x_{new} = \frac{x - \mu(X)}{\sigma(X)}$$
\subsection{Hipóteses}
Para se estabelecer uma hipótese de classificação, não se podem utilizar os métodos utilizados nas regressões como o método dos mínimos quadrados uma vez que esses métodos tentam minimizar distância entre a hipótese e os elementos.
O que se pretende para classificação é utilizar probabilidade e não distância como fator de separação.
Veja-se por exemplo uma separação pelo método dos mínimos quadrados (1ª figura) e uma regressão logística (2ª figura):[imagens]
\section{Regressão logística}
Um problema de classificação não pode utilizar regressões convencionais para delimitar os dados. As regressões tentam prever onde é mais provável a aparição de um novo elemento, no entanto uma classificação não procura pelo local de maior probabilidade de ocorrência de um novo ponto, procura pelo local em que classes são equi-prováveis. Caso fosse feita uma separação de classes pelo método dos mínimos quadrados, e uma das classes de classificação estivesse muito mais dissipada pelo espaço, a regressão iria tender para ela, contrariamente ás classes com dados mais concentrados.[imagem]\\
Uma regressão logística contrariamente ás regressões convencionais funciona encontrando o hiperplano de igual verosimilhança entre classes. Um ponto muito distante da hipótese de divisão de classes não afeta muito o resultado.\par
O nome "regressão logística" deve-se ao facto da regressão ser efetuada nos dados recorrendo a uma função logística, no entanto não resolve problemas de previsão de dados contínuos (regressões). Os seus resultados são binários contrariamente às regressões.
$$\text{Função logistica: } g(\vec x, \widetilde w) = \frac {1}{1+e^{-(\vec w ^T \vec x + w_0)}}$$
\section{Lazy Learning}
O conceito de \textit{lazy learning} (aprendizagem preguiçosa) consiste na constituição de modelos/classes de hipóteses de forma dinâmica à medida que os dados de treino são adicionados.\\
A principal vantagem desta caraterística que pode ser utilizada em alguns classificadores, é que permite a mutação do modelo em tempo real, sem carecer de novo treino com a integralidade dos dados.
\section{k-Vizinhos mais próximos (k-NN)}
O algoritmo k-Vizinhos mais próximos (abreviado k-NN, do inglês \textit{k-nearest neighbors}) é um potencial classificador.\\
Enquanto classificador é caraterizado por poder recorrer a \textit{lazy learning} (conforme visto acima) consoante a sua implementação. Assim sendo não requer um modelo pré-treinado.\par
Este algoritmo ordena os vizinhos de um elemento por ordem de proximidade das caraterísticas, carecendo de um parâmetro $k$ que indica o numero de vizinhos a considerar.
Para ordenar elementos admite diversas definições de distância, como a de \textit{Manhattan}, a euclidiana, a de \textit{Hamming}, etc... cada uma servido para propósitos distintos.
Por exemplo a distância de \textit{Manhattan} baseia-se na soma das diferenças absolutas nos eixos: $(1,1) \text{ até } (5,5) \text{ é } 4 + 4 = 8$ enquanto a distância euclidiana funciona por base na norma da soma dos vetores.\\
As distâncias comuns são baseadas na formula de \textit{Minkowski}:
$$ D_{x, x'} = \sqrt[p]{\sum_d |x_d - x_d'|^p} $$
Com esta formula a distância de \textit{Manhattan} é representada com $p=1$ e a euclidiana com $p=2$.\par
\subsection{Diagramas de Voronoi}
Para ilustrar um espaço bidimensional é possível recorrer a um diagrama de \textit{Voronoi}, com polígonos a delimitar as regiões em que cada classe é a que verifica o numero de vizinhos mais próximos. [Continuar...]
\section{Classificador de Bayes}
Pela \textbf{regra de Bayes} pode-se concluir que a probabilidade de uma amostra com vetor de caraterísticas $x$ pertencer à classe $c$ é dado por:
$$P(C=c|X=x)=\frac{P(C=c)P(X=x|C=c)}{P(X=x)}$$
Uma vez que a regra de Bayes com caraterísticas $x$ vai sempre resultar numa divisão por $P(X=x)$ podemos dizer que há proporcionalidade e simplificar a expressão para:
$$P(C=c|X=x)\propto P(C=c)P(X=x|C=c)$$
Pela regra do produto sabemos que $P(C=c)P(X=x|C=c)$ é a distribuição conjunta $P(C=c,X=x)$.\\
Computamos á parte uma tabela que a representa, sendo que podemos ainda escolher a melhor classe para cada exemplo, temos assim o \textbf{classificador de Bayes}:
$$C^{Bayes}=\underset{c\in \{0,1,\dots,N\}}{argmax} P(C=c,X=x)$$
O problema do classificador de Bayes é que implica que hajam dados para todas as combinações possíveis do vetor $x$, não consegue prever uma combinação que ainda nunca tenha tenha sido vista mesmo que seja composta por $x_i$'s que tornem a hipótese quase garantida.
Assim sendo é muito raro aplicar-se este classificador dada a impraticabilidade de fazer a amostragem de dados suficientes.
\section{Naïve Bayes}
O classificador Naïve Bayes é uma variação do classificador de Bayes que assume que todas as caraterísticas são condicionalmente independentes[confirmar]. Essa assunção reduz drasticamente a quantidade de dados necessários.\\[0.2cm]
Tem-se que para caraterísticas independentes a seguinte expressão está correta:
$$ p(x_i | C_k, x_1, \dots , x_{n-1}) $$
Por base nesse facto, é possível alterar o classificador de Bayes para se tornar:
$$C^{\text{Naïve Bayes}} = \underset{k\in \{0,1,\dots,K\}}{argmax} \> ln\> p(C_k) + \sum^N_{j=1} ln \> p(x_j | C_k)$$
\section{Máquina de Vetores de Suporte}
Uma máquina de vetores de suporte (normalmente chamada de SVM, do inglês \textit{support vector machine}) é um conceito para criação de classificadores.
\subsection{Classificador de margem máxima}
A classificação por base numa regressão logística permite o ajuste da fronteira.\\
Relembre-se que a regressão logística se baseia na minimização de:
$$-\sum^N_{n=1}{[t_m ln(g_n) + (1-t_n) ln(1-g_n)]}$$
Com:
$$g_n = \frac{1}{1 + e^{(\vec{w}^T \vec{x_n} + w_0)}}$$
Portanto uma alteração na magnitude de $\tilde{w}$ coloca o discriminante em locais diferentes. [ilustração]\\[0.2cm]
Com regularização pode obrigar-se $\tilde{w}$ a ser menor, o que distancia o discriminante dos seus pontos mais próximos, maximizando a sua margem. [porquê?]\\[0.2cm]
Um \textbf{classificador de margem} obtém uma margem até ao discriminante. Se esse classificador for de \textbf{margem máxima}, então a margem é a maior que pode ser obtida perante todos os discriminantes possíveis.\\[0.2cm]
Sabendo (álgebra linear) que a distância absoluta até ao discriminante é dada por:
$$\frac{\vec{w}^T \vec{x_n} + w_0}{||\vec{w}||}$$
É conceptualmente possível obter o discriminante que obtém a margem máxima perante todas as $Y$ classes.\\
Os pontos que incidem na margem designam-se os \textbf{vetores de suporte}, e para classes linearmente separáveis são os pontos mais próximos do discriminante.\\
Para encontrar o hiperplano que maximiza a distância aos vetores de suporte tem-se o seguinte problema:
$$\underset{\vec{w}, w_0}{argmax}
\left(
\underset{j}{min}
\frac{y_j(\vec{w}^T \vec{x_j} + w_0)}{||w||}
\right)$$
Não fosse o facto desta função não ser diferenciável e portanto não ter resultados conclusivos.\\[0.2cm]
Este problema pode no entanto ser resolvido com as condições de Karush-Kuhn-Tucker, recorrendo a multiplicadores de Lagrange.
\subsection{Classificador com margens suaves}
Uma SVM (linear) só funciona se as classes forem linearmente separáveis. Quando não são se pode implementar um SVM com margens fixas, pode relaxar-se esse requerimento e permitir que as margens sejam "suaves", isto é, permitam a penetração por parte de alguns pontos para lá do limiar da margem.\\
No lugar do requerimento para dimensionamento da margem coloca-se $\xi$, uma variável de folga.
$$\text{Margens rigidas: } y_n(\vec{w}^T \vec{x}_n + w_0) \geq 1, \forall n \in N$$
$$\text{Margens suaves: } y_n(\vec{w}^T \vec{x}_n + w_0) \geq 1 - \xi_n, \forall n \in N$$
\begin{itemize}
\item $\xi \geq 0$ visto ser a uma distância.
\item $1 > \xi_n > 0$ então o ponto encontra-se dentro da margem.
\item $\xi_n > 1$ então o ponto $\vec{x}$ foi mal classificado.
\item Quer-se maximizar a margem, minimizando $||\vec{w}||^2$ mas penalizando desvios da margem\\
$\displaystyle C \sum_{n=1}^N \xi_n + \frac{1}{2}||\vec{w}||^2$
\end{itemize}
Este classificador funciona se houver uma quase linearidade, em que poucos pontos entram nas margens e não as excedem muito.
\subsection{Kernel tricks}
Um \textit{\textbf{kernel trick}} é a aplicação de uma \textbf{kernel function} função cujo resultado é o produto interno de dois vetores após aplicação de uma função.
$$K(\vec{x}_1,\vec{x}_2) = \phi(\vec{x}_1)^T \phi(\vec{x}_2)^T$$
É útil nos cenários em que é mais eficiente pré-computar as operações dada potencial simplificação de cálculos.
\section{Classificação com múltiplas classes}
Existem classificadores que naturalmente lidam bem com diversas classes, como o k-NN que opta pela classe com mais vizinhos ou o Naïve Bayes que opta pela maior probabilidade conjunta.
\subsection{Uma classe contra as restantes}
Neste cenário criam-se para $k$ classes $k-1$ classificadores.
\begin{itemize}
\item Cada um dos classificadores classifica individualmente uma das classes.\\
As restantes classes são consideradas uma só durante a classificação.
\item O classificador final é a sobreposição dos classificadores individuais.
\item A ausência de classificação no classificador final representa a classe que não foi classificada.
\item Este método deixa áreas de ambiguidade, onde os classificadores sobrepõem.
\end{itemize}
\subsection{Um contra um}
Criam-se para $k$ classes $k(k-1)/2$ classificadores, que correspondem ás combinações de classes duas a duas.\\
Classifica-se assim por exclusão de classes.\\
Este método também resulta em locais ambíguos em que podia ser uma de varias classes.
\subsection{Uma contra todas}
\begin{itemize}
\item Obtém-me os classificadores como se fosse no procedimento de uma contra as restantes.
\item Unem-se os classificadores, mas nas interseções vigora o classificador cujo máximo da função de decisão é maior.
\end{itemize}
Este método tem o problema de que os classificadores podiam ter níveis de confiança diferentes, arriscando-se a fazer má classificação em algumas classes.
\subsection{Enviesamento e variância}
Quando um modelo não se consegue ajustar aos dados existe um grande enviesamento nas previsões efetuadas por base nesse modelo.\\
A \textbf{enviesamento} é o desvio da estimação média ao valor real. O mesmo pode ser definido
$$\text{enviesamento} = (\text{média previsões} - \text{valor real})^2$$
Num modelo o enviesamento médio é:
$$\text{enviesamento} = \frac{1}{N}\sum_{n=1}^N(\text{média previsões} - \text{valor real})^2$$
A \textbf{variância} é a dispersão das previsões em torno da sua média. Para um ponto (e perante $M$ hipóteses):
$$\text{variância} = \frac{1}{M}\sum_{m=1}^M (\text{média previsões} - \text{hipotese}_m)^2$$
Num modelo a variância é dada:
$$\text{variância} = \frac{1}{NM}\sum_{n=1}^n \sum_{m=1}^M (\text{média previsões}_{\text{ponto }n} - \text{hipotese}_m)^2$$
Numa função de erro quadrático o erro esperado é:
$$E((\text{previsão} - \text{valor real})^2) =\text{enviesamento} + \text{variância} + \text{ruido} =$$
$$= \left(E(\text{previsão}) - E(\text{valor real})\right)^2 +
E\left((\text{previsão}-E(\text{previsão}))^2)\right) +
E\left((\text{valor real}-E(\text{valor real})\right)^2)$$
\chapter{Ensembling}
\textbf{Ensembling} chama-se aos métodos que agregam diversos algoritmos de classificação.
\section{Bootstrap aggregating - Bagging}
O método de \textbf{bootstrap aggregating} (abreviado \textbf{bagging}) é um método de \textbf{ensembling} que consiste no treino de diversos modelos com algoritmos distintos e subsequente aplicação aos dados em modo análogo a uma votação.\\[2mm]
Em regressões a votação do resultado pode por exemplo ser feita por base na média dos diversos modelos. Se for feita por base na mediana o método designa-se \textbf{bragging}.\\[2mm]
Em problemas de classificação a votação é por maioria.\\
Com $T$ classificadores com probabilidade de sucesso $p$, a probabilidade da classificação por maioria ser correta é:
$$\sum_{k=T/2+1}^{T}\binom{T}{k} p^k (1-p)^{T-k}$$
No entanto isto é assumindo completa independência entre os classificadores. Se houver correlação entre os resultados de diversos classificadores a eficácia de \textit{bagging} desce significativamente. Alem disso idealmente os classificadores desejados são \textbf{classificadores instáveis}, que tem alta variância.\\
Classificadores como SVM com baixa constante de regularização ou k-NN não são bons candidatos a \textit{bagging} por serem \textbf{classificadores estáveis} que são pouco afetados por alterações no conjunto de treino.
\clearpage
\section{Boosting}
Um algoritmo de \textbf{boosting} resulta uma ponderação de classificadores.
\subsection{AdaBoost}
O \textbf{adaptative boosting} (\textbf{AdaBoost}) obtém uma combinação linear de classificadores fracos (pouco melhores que aleatoriedade) que resultam num classificador forte.
$$\text{Com }
I(a \neq b) =
\begin{cases}
1 , a\neq b\\
0 , a=b
\end{cases}$$
O algoritmo é dado por:
\begin{enumerate}
\item Inicializa-se os pesos de todos os $N$ classificadores:
$$w_n = \frac{1}{N}$$
\item Um classificador é treinado de forma a minimizar o erro ponderado do conjunto de treino:
$$J_m = \sum_{n=1}^{N}w_m^n I(y_m(x^n)\neq t^n)$$
\item Computa-se o erro ponderado do classificador e o peso do classificador no \textit{ensembling}:
$$\epsilon_m = \frac{\sum\limits_{n=1}^N w_m^n I(y_m(x^n)\neq t^n)}{\sum\limits_{n=1}^N w_m^n} \quad \quad \alpha_m = ln \frac{1 - \epsilon_m}{\epsilon_m}$$
\item Então usa-se $\alpha_m$ para atualizar os pesos dos pontos:
$$w^n_{m+1} = w_m^n exp (a_m I(y_m(x_n) \neq t^n))$$
A função $I$ aumenta os pesos dos pontos mal classificados (?).\\
Ajusta-se um novo classificador ao conjunto de treino com os novos pesos e repete-se o processo até que o erro ponderado de treino seja 0 ou $\geq 0.5$.
\end{enumerate}
O classificador final é dado por:
$$\text{AdaBoost}(x) = sign \sum^M_{m=1} a_m y_m(x)$$\\[2mm]
À utilização de AdaBoost com \textbf{decision stumps}(por fazer: secção) chama-se de \textbf{stumping}.
\chapter{Análise de dados}
\section{Visualização}
\subsection{Histograma}
(Por fazer)
\subsection{Diagrama de Extremos e Quartis}
(Por fazer)
\subsection{Diagrama de Dispersão}
(Por fazer)
\clearpage
\section{Seleção de Caraterísticas}
Os dados frequentemente tem mais detalhe do que o necessário para a aprendizagem. Podem incluir caraterísticas desnecessárias ou com pouca correlação com o que se procura concluir.
Quando existem demasiadas caraterísticas em análise aumenta-se substancialmente o tempo de computação e pode resultar em problemas como sobreajuste.\\
Tipicamente faz-se \textbf{seleção de caraterísticas}, a escolha de caraterísticas com alto relevo em detrimento das pouco relevantes.
\subsection{Filtragem}
À exclusão das caraterísticas pouco relevantes do processo de aprendizagem chama-se de \textbf{filtragem}. Uma filtragem pode ser \textbf{univariável} ou \textbf{multivariável} consoante resulte da análise individual ou conjunta das caraterísticas.\\[2mm]
Filtragem univariável pode resultar de diversos critérios.\\
A \textbf{independência estatística} é um desses critérios uma vez que uma caraterística que é independente das diversas classes não é útil para as prever. A independência pode ser avaliada recorrendo ao \textbf{teste qui-quadrado} ($\chi ^2$), que calcula a probabilidade de obtenção de uma amostra durante a tiragem.\\
Para frequências observadas $O_n$ e frequências esperadas $E_n$, o valor do teste qui-quadrado é:
$$\chi^2 = \sum_{i=1}^N \frac{(O_i - E_i)^2}{E_i}$$
Haja uma caraterística com $K$ categorias de valores a ser utilizada para um problema com $C$ classes, e sejam $O_{kc}$ a frequência de observações e $E_{kc}$ a frequência esperada, respetivamente.\\
O teste tem $(K-1)(C-1)$ graus de liberdade e é dado por:
$$\chi^2 = \sum_{k=1}^K \sum_{c=1}^C \frac{(O_{kc} - E_{kc})^2}{E_{kc}}$$
Quanto menos o valor de $\chi^2$ maior a independência entre a caraterística e a classe.\\[5mm]
Outro critério pode ser a variância de grupos (de dados/de caraterísticas?), sendo aplicado o \textbf{teste-F} para análise de variância (\textbf{ANOVA}), um teste que compara a variância entre grupos com a variância dentro dos grupos. Um teste-F com um valor baixo implica uma independência provável e denuncia a caraterística como pouco relevante.\\[2mm]
Já a filtragem multivariável baseia-se na correlação entre variáveis. Quando duas caraterísticas estão correlacionadas são redundantes e uma delas pode ser descartada.\\[2mm]
Quando uma má caraterística irrelevante não é descartada causa má performance nas hipóteses que a usam extensivamente, sendo a performance outro fator que denuncia a qualidade de uma caraterística. \\ Existem \textbf{wrapper methods}, algoritmos de classificação de caraterísticas, que efetuam testes de performance em subconjuntos das caraterísticas.\\
Quando um \textit{wrapper method} itera em todos os subconjuntos de caraterísticas é determinístico.\\
\textbf{Seleção sequencial para a frente} é o processo de começar com um conjunto vazio, e iterativamente testar qual a melhor caraterística a juntar ao conjunto.\\
Para contraste, com \textbf{eliminação sequencial para a trás} faz-se o reverso, parte-se de um conjunto com todas as caraterísticas  e iterativamente retira-se a pior.\\[2mm]
Existem ainda \textbf{wrapper methods não-determinísticos} que tentam alcançar o mesmo objetivo recorrendo a métodos como a recristalização simulada ou algoritmos genéticos.\\[2mm]
Por fim existem algoritmos de aprendizagem que selecionam por si as melhores caraterísticas. A esta propriedade designa-se de \textbf{seleção de caraterísticas embutida}.\\
Um exemplo de um algoritmo que a verifica são as árvores de decisão com limite de profundidade.
\chapter{Clustering}
\section{K-Means}
O algoritmo \textbf{K-Means} funciona definindo $k$ \textbf{protótipos} de \textbf{cluster} e ajustando-os iterativamente até serem \textit{clusters}.
Esses \textbf{protótipos} são \textbf{centroides}, que representam os centros das partições de um diagrama de \textit{Voronoy}.
\begin{wrapfigure}{r}{0.3\textwidth}
  \vspace{-20pt}
  \begin{center}
    \includegraphics[width=0.2\textwidth]{images/centroids.png}
  \end{center}
  \vspace{-20pt}
  \caption{O \textbf{centroide} de um triângulo, a média aritmética dos seus pontos.}
  \vspace{10pt}
  \begin{center}
    \includegraphics[width=0.3\textwidth]{images/kmeans-classification-issues.png}
  \end{center}
  \vspace{-20pt}
  \caption{A classificação de um conjunto de dados com duas caraterísticas utilizando o k-Means. Autoria: \textit{Chire}/Wikimédia}
  \vspace{-50pt}
\end{wrapfigure}
\begin{enumerate}
\item O algoritmo começa definindo as localizações iniciais $L$ dos protótipos $p$.
$$p_1=L_1,\quad p_2=L_2 \quad \dots \quad p_k = L_k$$
Essas localizações podem ser aleatórias se nada se souber do problema.\\
Também podem ser o resultado de métodos como o ``\textbf{Forgy}" que gera protótipos a partir de conjuntos aleatórios de pontos.
\item Todos os pontos no conjunto de treino são atribuídos ao protótipo mais próximo.
Nesta atribuição é utilizada a distância euclidiana.\\
Seja $X$ o conjunto dos dados:
$$\forall i \in \text{dados},\quad min = \underset{j}{\operatorname{argmin}} \text{ Distância}(X_i, p_j),\quad X_i \in p_{min}, X_i \notin p_{\neq min}$$
\item Todo o protótipo é ajustado para voltar a ser o centroide do conjunto que representa.
$$\forall i, c_j = \frac{1}{\#c_j}\sum_{i \in c_j} X_i$$
\item Se no passo anterior fez os pontos mudarem de protótipo o algoritmo volta ao segundo passo, caso contrario os protótipos tornam-se \textit{clusters}.
\end{enumerate}
Este algoritmo é simples e rápido. Os cálculos são simples para um computador e não são sujeitos a erros de computação como arredondamentos.
Em contrapartida, o algoritmo assume que todos os protótipos tem a mesma influência sobre o espaço adjacente, criando uma partição de \textit{Voronoy} com erros graves quando se lida com \textit{clusters} adjacentes de magnitudes diferentes.
\pagebreak
\section{DBSCAN}
O algoritmo \textbf{DBSCAN} (abreviação para \textbf{D}ensity-\textbf{B}ased \textbf{S}patial \textbf{C}lustering of \textbf{A}pplications with \textbf{N}oise) é um algoritmo que funciona recursivamente por via de árvores. Os pontos dos dados como \textbf{núcleo}, \textbf{fronteira} ou \textbf{ruído} consoante a sua vizinhança, e são ligados a alguns dos seus vizinhos de forma a que os clusters fiquem em árvores distintas.
\vspace{5mm}
\begin{wrapfigure}{r}{0.3\textwidth}
    \begin{center}
        \includegraphics[width=0.3\textwidth]{images/dbscan_point_types.png}
        \caption{Core in red, border as yellow, noise as blue. Copyright \textit{Chire}/Wikimédia}
	\end{center}
	\vspace{-50pt}
\end{wrapfigure}
A atribuição dos pontos é a seguinte:
\begin{itemize}
\item \textbf{Núcleo} - Pontos que tenham pelo menos \textit{minPontos} na sua vizinhança.
\item \textbf{Fronteira} - Pontos que tenham menos de \textit{minPontos} na sua vizinhança.
\item \textbf{Ruído} - Pontos que não tenham pontos núcleo na sua vizinhança.
\end{itemize}
Para definir o algoritmo são necessários dois critérios um valor para \textit{minPontos} e a distancia máxima na qual um ponto é considerado vizinhança (um raio de uma hiperesfera portanto).\\
Estes requisitos moldam o algoritmo aos dados com o qual vai trabalhar, o que infelizmente o torna pouco genérico.\\[2mm]
Quando se trabalha com dados esparsos os critérios tem de aumentar, caso contrario os pontos são classificados indevidamente como ruído.
Por outro lado, quando se trabalha com dados densos, os critérios tem de diminuir ou os \textit{clusters} são unificados.\\[2mm]
A aplicação do algoritmo começa por se marcar um ponto, atribuir um tipo, e saltar para a sua vizinhança, com uma construção em profundidade.\\
Assim que não existam mais pontos não anexados na vizinhança de qualquer ponto da árvore, repete-se o mesmo procedimento até se esgotarem todos os pontos do conjunto de dados.
\clearpage
\section{Modelo Mistura Gaussiano}
\begin{wrapfigure}{r}{0.3\textwidth}
    \begin{center}
        \vspace{-20pt}
        \includegraphics[width=0.3\textwidth]{images/mixture-model.png}
        \caption{Um modelo mistura com duas distribuições gaussianas.}
    \end{center}
    \vspace{-50pt}
\end{wrapfigure}
O \textbf{Modelo Mistura Gaussiano}(abreviado \textbf{GMM}) é um algoritmo de \textit{clustering} baseado em probabilidade.\\
\textbf{Gaussiano} refere-se à \textbf{distribuição probabilística Gaussiana}(Normal $(\mu=0, \sigma=1)$), com um \textbf{modelo mistura} sendo o modelo probabilístico que assume que as probabilidades são dada por uma distribuição mista (com Gaussianas neste caso).\\
Com este método os modelos probabilísticos são tipicamente calculados de forma iterativa.
\begin{figure}[ht]
\captionsetup{singlelinecheck = false, justification=justified}
\includegraphics[width=0.42\textwidth]{images/gaussian-level-curves.png}
\caption{Ilustração do GMM.}
\end{figure}
\end{document}
