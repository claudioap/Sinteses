\documentclass[]{report}
\usepackage[a4paper, total={7in, 8.5in}]{geometry}
\usepackage[portuguese]{babel}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{color}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\begin{document}
\begin{titlepage}
	\centering
	\vspace{5cm}
	{\huge\bfseries Inteligência Artificial\par}
	\vspace{1cm}
	{\scshape\Large Síntese baseada no conteúdo lecionado na\\
	 FCT/Universidade Nova de Lisboa\par}
	\vspace{2cm}
	Adaptado por:\\
	{\Large \textit{Cláudio Afonso de Sousa Pereira}\\
	(sinteses$\text{@}$claudiop$.$com)\par}
	\vspace{1cm}
	Do material lecionado por:\\
	{\Large \textit{João Alexandre Carvalho Pinheiro Leite}\\
	(jleite$\text{@}$fct$.$unl$.$pt)\par}
	\vspace{1cm}
	{\large \today\par}
	\vfill
	Adaptação licenciada:\\
	\href{http://creativecommons.org/licenses/by-sa/4.0/}{\includegraphics[scale=0.8]{ccbysa.png}}
\end{titlepage}
\tableofcontents
\chapter{Definição}
\section{O que é}
A definição genérica e formal de IA segundo a \textit{Association for the Advancement of Artificial Intelligence} é:
\begin{quote}
A compreensão científica dos mecanismos subjacentes ao pensamento e ao comportamento inteligente e sua incorporação nas máquinas.
\end{quote}
Pode no entanto ser interpretada de diversas formas distintas:
\begin{table}[htbp]
\begin{tabular}{l | l}
Sistemas que pensam como humanos & Sistemas que agem como humanos \\ \hline
Sistemas que pensam racionalmente & Sistemas que agem racionalmente \\
\end{tabular}
\end{table}
\subsection{Sistemas que pensam como humanos}
Pensar como humanos requer uma teoria a detalhar a mente humana para validar o comportamento do sistema de inteligência artificial.\\
Tal teoria pode ser obtida das seguintes formas:
\begin{itemize}
\item \textbf{Introspeção} - Por captação de pensamentos
\item \textbf{Experiências Psicológicas} - Por observação de ações
\item \textbf{Imagens cerebrais} - Por observação do cérebro
\end{itemize}
Perante uma teoria suficientemente detalhada, é possível implementar a mesma num computador.\\
As áreas que tentam desenvolver teorias da mente são:
\begin{itemize}
\item \textbf{Ciência cognitiva} - Por técnicas psicológicas
\item \textbf{Neurociência Cognitiva} - Por técnicas neurológicas
\end{itemize}
A desvantagem deste método de conceção de inteligência artificial é que a obtenção de dados e posterior validação é efetuada por via de experimentação em humanos, e após décadas de investigação ainda não foi possível explicar a inteligência humana.\\
Por estes motivos esta área de estudo é considerada distinta da inteligência artificial, apesar de ter muito em comum.
\subsection{Sistemas que pensam racionalmente}
Um sistema que pensa racionalmente é um que tem fundamentos em lógica.\\
A lógica pode ser vista neste contexto como uma interseção de Matemática e Filosofia, e seria possível criarem-se sistemas de raciocínio por base nestas vertentes, no entanto:
\begin{itemize}
\item Nem todos os comportamentos inteligentes são lógicos.
\item Não é simples deliberar o objetivo do pensamento ou quais os pensamentos a ter com lógica.
\item É de elevada complexidade descrever lógica.
\end{itemize}
\subsection{Sistemas que agem racionalmente}
Sistemas que agem racionalmente são construidos por base em \textbf{agentes racionais}.\\
Um \textbf{agente} é entidade uma definida por:
\begin{itemize}
\item Agir autonomamente
\item Percecionar o ambiente
\item Persistir no tempo
\item Adaptar-se a mudanças
\item Criar e perseguir objetivos
\end{itemize}
Um agente é racional quando age para obter o melhor resultado, ou, perante incerteza, o melhor resultado esperado.\\
É mais adequado para desenvolvimento cientifico do que as abordagens baseadas no comportamento humano.
\section{Fundações}
A inteligência artificial é constituída por muitas áreas de estudo, e pode ser aplicada a muitas mais. 
\subsection{Filosofia}
Para que se faça inteligência artificial tem de se conseguir responder às questões:
\begin{itemize}
\item Podem regras formais ser usadas para inferir conclusões válidas?
\item Como é que a mente emerge de um cérebro físico?
\item De onde vem o conhecimento?
\item Como é que o conhecimento leva à ação?
\end{itemize}
No entanto a inteligência artificial contribui para a filosofia no estudo de:
\begin{itemize}
\item Lógica
\item Métodos de raciocínio
\item Compreensão da mente como um sistema físico
\item Fundamentos da aprendizagem
\item Linguagem
\item Racionalidade
\end{itemize}
\subsection{Matemática}
Tem de se conseguir responder as questões:
\begin{itemize}
\item Quais são as regras formais para inferir conclusões válidas?
\item O que pode ser computado?
\item Como raciocinar com informação incerta?
\end{itemize}
Sendo o retorno no estudo de:
\begin{itemize}
\item Representação formal e prova
\item Algoritmos
\item Computação
\item Determinação da decibibilidade
\item Determinação da tractibilidade [rever e acabar isto]
\item Probabilidades
\end{itemize}
\chapter{Agentes}
\section{Caraterísticas dos agentes}
Agentes são sistemas que agem num dado \textbf{ambiente}.
Um agente perceciona o ambiente através de \textbf{sensores} e age nele com \textbf{atuadores}.
\begin{itemize}
\item Corpo
\item Localização (No tempo e espaço)
\item Capacidades (Sensores e atuadores)
\item Decisão
\end{itemize}
Existem diversos tipos de agentes conhecidos:
\begin{itemize}
\item Biológicos\\
Os \textbf{sensores} são olhos, ouvidos, pele, ...\\
Os \textbf{atuadores} são as mãos, pernas, boca, ...
\item Robóticos\\
Os \textbf{sensores} são câmaras, sensores de proximidade, ...\\
Os \textbf{atuadores} são motores,...
\item Computacionais\\
Os \textbf{sensores} são um teclado, rato, ligações de rede, ...\\
Os \textbf{atuadores} são o ecrã, uma placa de controlo, um email enviado, ...
\end{itemize}
\section{Definição sistemática}
Um \textbf{ambiente} carateriza-se por conjuntos de \textbf{estados} $E$.\\
Os estados sofrem transições não deterministas:
$$[ \text{Ambiente: } E \times A \rightarrow 2^E] \text{(o que é isto?)}$$
O agente é constituído por duas funções:
$$[\text{Percepção: }: E \rightarrow P]$$
$$[\text{Ação }: P^{\star} \rightarrow A]$$
e implementa a função:
$$[\text{Agente }: E^\star \rightarrow A]$$
\section{Agentes racionais}
Um agente racional faz o que lhe é mais benéfico.\\
O beneficio é medido por via de uma \textbf{medida de desempenho} que é o critério de avaliação do agente.
Assim sendo, um agente racional é um agente que maximiza o valor esperado da medida de desempenho.\\
Note-se que racionalidade não implica:
\begin{itemize}
\item \textbf{Omnisciência} (Tudo saber)
\item \textbf{Derividência} (Tudo prever)
\item \textbf{Sucesso}
\end{itemize}
No entanto pressupõe:
\begin{itemize}
\item \textbf{Obtenção de informação} e \textbf{exploração}
\item \textbf{Aprendizagem}
\item \textbf{Autonomia}
\end{itemize}
\section{Performance measure environment}
PEAS
[Por fazer]
\clearpage
\section{Propriedades dos ambientes}
\subsection{Observabilidade}
Um ambiente é \textbf{totalmente observável} se o agente for omnisciente, isto é, souber o estado atual de tudo.\\
Por outro lado é \textbf{parcialmente observável} se o agente só conseguir obter alguma informação em cada instante.
\subsection{Determinismo}
Um ambiente é \textbf{determinista} se as ações do agente sobre o ambiente forem deterministas.\\
Se apenas as ações do próprio agente forem determinísticas, no entanto as dos restantes agentes não forem, o ambiente é \textbf{estratégico}.\\
Caso o ambiente não seja determinístico é \textbf{estocástico}.
\subsection{Coiso atómico cenas}
[Por fazer]
\subsection{Dinamismo}
Se o ambiente não alterar durante a deliberação do agente, então é \textbf{estático}.\\
Se a o ambiente se alterar por fatores externos é \textbf{dinâmico}.\\
Se a medida de desempenho alterar e com ela a perceção do ambiente, o ambiente é \textbf{semi-dinâmico}.
\subsection{Espaço de ações}
Se o ambiente tiver um numero finito de ações e todas elas estejam bem definidas, o ambiente é \textbf{discreto}.\\
Caso contrario é \textbf{continuo}.
\subsection{Partilha}
Se o agente for o único no ambiente, o ambiente tem \textbf{agente único}.\\
Caso contrario é \textbf{multi-agente}.
\clearpage
\section{Propriedades dos agentes}
Um agente pode verificar uma combinação das seguintes propriedades:
\subsection{Racionalidade}
Maximiza o desempenho em função dos dados obtidos
\subsection{Reatividade}
Responde em tempo útil a mudanças no ambiente.
\subsection{Proactividade}
Tem iniciativa em vez de apenas reagir.
\subsection{Comunicação}
Comunica com os outros agentes.
\subsection{Autonomo}
Aprende e adapta-se com experiências anteriores
\subsection{Mobilidade}
Consegue deslocar-se
\subsection{Caráter}
Apresenta um estado emocional e uma propriedade própria.
\clearpage
\section{Arquiteturas de agentes}
Os agentes tem uma arquitetura associada ao seu funcionamento.\\
As seguintes são arquiteturas comuns, e todas elas podem ser transformadas em agentes com capacidades de aprendizagem. [needs sauce]
\subsection{Agente reativo puro}
Um agente reativo puro perceciona o mundo pelos seus sensores e recorre a um conjunto de regras suas para decidir o que fazer. Como o nome indica, para cada ação deverá de ter uma reação.
\paragraph{Programas Teleo-Reativos (Nilsson)}.\\
São programas definidos por um uma sequência de regras.
$$\{\{c_1 \rightarrow a_1\}, \{c_2 \rightarrow a_2\}, \dots, \{c_n \rightarrow a_n\}\}$$
Cada $c_k$ é uma condição dada por uma conjunção de preposições booleanas e cada $a_k$ é uma ação a executar.\\
Opta-se sempre por executar a primeira condição que se verifique verdadeira.\\[0.2cm]
Um agente reativo puro é baseado num programa Teleo-Reativo.
\subsection{Agente reativo baseado em modelos}
Este agente é uma modificação do agente reativo puro que o permite memorizar as mudanças no mundo.
\subsection{Agente guiado por objetivo}
Um agente que considera o impacto das ações no mundo, tanto para as ações passadas (avalia o resultado que tiveram), como para ações futuras (tenta prever as eventuais consequências).\\
A partir das considerações, calcula o que pensa serem as melhores ações para chegar ao objetivo.
\subsection{Agente guiado com função de utilidade}
Um agente similar ao guiado por objetivo, mas considera a utilidade em vez dos objetivos, isto é, durante o seu tempo de execução, tenta maximizar a sua utilidade em todos os instantes de tempo
\section{Agentes aprendizes}
[TODO]
\section{Representações internas dos agentes}
\begin{itemize}
\item Atómica\\
Sem uma estrutura interna
\item Fatorizada\\
Com um numero finito de atributos atómicos
\item Estruturada\\
Com relações entre objetos
\end{itemize}
\chapter{Procura Cega}
Um \textbf{problema de procura} é um problema cuja solução é uma sequência de ações que levam de um estado inicial ao estado final.\\
Um problema de procura lida com \textbf{procura cega} se o ambiente só for observável nos estados já observados. [factualy correct?, ver formulação]
\section{Formulação de um agente}
Para se formular um agente que resolva problemas de procura [cega?] tem de se assumir que o ambiente é:
\begin{itemize}
\item Estático
Não muda durante a resolução
\item Observável - O agente sabe o estado corrente
\end{itemize}
\chapter{Procura Heurística}
\section{Algoritmos iterativos de melhoramento}
Estes algoritmos partem de uma potencial solução ao problema em análise, e dispõem de uma medida de quão boa é a sua qualidade. Cada iteração tenta arranjar uma solução alternativa à atual que apresente mais qualidade.\\
Note-se que não é no entanto garantida a obtenção da solução ótima.\\[0.5cm]
O problema tem de ser formulado como um problema de otimização ou seja, tem de ser definido:
\begin{itemize}
\item O espaço de potenciais soluções, e o que pode ser uma solução (representada $x$).
\item A função $f(x)$ a ser otimizada.
\item O que se entende por "pequenas alterações", ou seja, qual a vizinhança de um $x$, $V(x)$.
\end{itemize}
\subsection{Aplicação ao problema do caixeiro viajante}
\chapter{Procura Local}
\chapter{Agentes Lógicos}
\section{Bases de conhecimento}
Uma base de conhecimento (abreviado KB, do inglês \textit{knowledge base}) é um conjunto de \textbf{frases} numa linguagem \textbf{formal}.
As bases de conhecimento permitem construir agentes de forma \textbf{declarativa}, através de duas ações:\\
\begin{tabular}{r l}
$TELL \Leftarrow $ & A ação da base de conhecimento informar o sistema.\\
$ASK \Leftarrow $ & A ação do sistema questionar a sua base de conhecimento.
\end{tabular}\\[0.2cm]
Os agentes podem então ser analisados pelo:
\begin{itemize}
\item Nível de conhecimento\\
(Ex: A quantidade de conhecimento)
\item Nível de implementação\\
(Ex: As estruturas de dados na base de conhecimento e estruturas que manipulam)
\end{itemize}
Tendo os mesmos de ser capazes de:
\begin{itemize}
\item Representar novos estados, ações, ...
\item Incorporar novas perceções.
\item Atualizar representações internas do mundo.
\item Deduzir propriedades escondidas no mundo.
\item Deduzir ações apropriadas.
\end{itemize}
Exemplo da formulação de um agente simples:
\begin{algorithm}
\caption{Exemplo da utilização de uma base de conhecimento}
\begin{algorithmic}
\Function{KB-Agent}{percept}
\State    static KB, base de conhecimento
\State           $t$, um contador que indica tempo
\State    TELL(KB, MAKE-PERCEPT-SENTENCE(percept, $t$))
\State    action $\gets$ ASK(KB, MAKE-ACTION-QUERY($t$))
\State    TELL(KB, MAKE-ACTION-SENTENCE(action, $t$))
\State    $t \gets t + 1$
\State \Return action
\EndFunction
\end{algorithmic}
\end{algorithm}
\section{Lógica}
\subsection{Noções}
Linguagens \textbf{lógicas} são linguagens formais para representação de informação que permitem extração de conclusões.\\[0.2cm]
A \textbf{sintaxe} define as frases permitidas na linguagem.\\
\indent Ex: Em aritmética $x + 2 \geq y$ é uma frase (preposição), no entanto $x2 + y >$ não é.\\[0.2cm]
A \textbf{semântica} define o significado das frases.\\
\indent Ex: Em preposições aritméticas a semântica define a verdade da preposição.
\subsection{Conclusões}
A uma \textbf{conclusão} (ou consequência) lógica, designa-se ao que obteve o seu valor semântico indiretamente, por via de outros elementos linguísticos. Por exemplo o numero 7 ser primo é uma consequência da sua não divisibilidade por outros números que não 1.\\[0.2cm]
Havendo uma base de conhecimento KB, conclui-se dela uma frase $\alpha$, se $\alpha$ é verdade sempre que KB é verdade. (representando-se esta conclusão $\text{KB }\models \alpha$, lida KB modela/conclui $\alpha$).\\[0.2cm]
Chama-se de \textbf{conclusão lógica} a uma relação entre frases que se baseia em \textbf{semântica}.
\subsection{Modelos}
Em lógica modelos são mundos formalmente estruturados dos quais se pode avaliar a veracidade de preposições.\\
Diz-se que $m$ é um modelo de uma preposição $\alpha$ se $\alpha$ é verdade em $m$.\\
Designa-se $M(\alpha)$ o conjunto de todos os modelos de $\alpha$.\\
Conclui-se portanto que se KB modela $\alpha$ ($\text{KB } \models \alpha$) então os modelos de KB são um subconjunto (ou iguais) aos modelos de $\alpha$ ($M(\text{KB}) \subseteq M(\alpha)$).\\
Ex: Sendo KB uma base de conhecimento que define as cadeiras que os alunos fizeram. Se $\alpha$ for a aprovação do João a Análise, então KB modela $\alpha$, é possível apurar $\alpha$ a partir de KB e $M(\text{KB}) \subseteq M(\alpha)$ verifica-se.
\subsection{Inferência}
Uma inferência lógica a método de obtenção de uma consequência lógica por base numa base de conhecimento. Representa-se de KB $\vdash_i \alpha$ obtenção da preposição $\alpha$ a partir de KB por base na inferência $i$.\\[0.2cm]
O procedimento de inferência $i$ é:
\begin{itemize}
\item \textbf{Fidedigno} (ou sólido): Se KB $\vdash_i \alpha$ implica que KB $\models \alpha$.
\item \textbf{Completo}: Se KB $\models \alpha$ implica que KB $\vdash_i \alpha$.
\end{itemize}
Quando um procedimento de inferência é fidedigno e completo responde a qualquer questão conhecida pela base de conhecimento.
[Colocar esquema ilustrativo, frasear melhor]
\section{Lógica proposicional}
A lógica proposicional é a lógica mais simples. Ilustra conceitos básicos por base em símbolos (variáveis) proposicionais para constituição de proposições (frases).\\
Se $P_1, P_2$ forem proposições, o seguinte também o é:
\begin{itemize}
\item $\neg P_1$ (Negação)
\item $P_1 \wedge P_2$ (Conjunção)
\item $P_1 \vee P_2$ (Disjunção)
\item $P_1 \Rightarrow P_2$ (Implicação)
\item $P_1 \Leftrightarrow P_2$ (Bicondicional)
\end{itemize}
Os modelos atribuem valores booleanos aos símbolos proposicionais.\\
$n$ símbolos admitem no máximo $2^n$ modelos, consoante as preposições existentes.\\[0.5cm]
A avaliação da veracidade de um modelo $m$ é feita por disjunção das suas preposições, sendo cada preposição decomposta em sub-preposições até ser constituída apenas por símbolos e as operações descritas acima. O valor da expressão final dita a validade do modelo.\\[0.2cm]
Uma tabela de verdade permite enumerar todos os $2^n$ modelos teoricamente possíveis, verificar quais é que respeitam a base de conhecimento, e se uma dada preposição é sempre verdade
\subsection{Equivalências}
Quando duas preposições são sempre iguais entre si, em todos os modelos, então são ditas \textbf{equivalentes}.\\
Equivalência entre dois modelos $\alpha, \beta$ representa-se $\alpha \equiv \beta$ e implica $\alpha \models \beta \wedge \beta \models \alpha$.\\
As seguintes são equivalências da lógica proposicional:
\begin{itemize}
\item $(\alpha \wedge \beta) \equiv (\beta \wedge \alpha)$, comutatividade.
\item $(\alpha \vee \beta) \equiv (\beta \vee \alpha)$, comutatividade.
\item $((\alpha \wedge \beta) \wedge \gamma) \equiv (\alpha \wedge (\beta \wedge \gamma))$, associatividade.
\item $((\alpha \vee \beta) \vee \gamma) \equiv (\alpha \vee (\beta \vee \gamma))$, associatividade.
\item $\neg(\neg \alpha) \equiv \alpha$, eliminação da dupla negação.
\item $(\alpha \Rightarrow \beta) \equiv (\neg \beta \Rightarrow \neg \alpha)$, contraposição.
\item $(\alpha \Rightarrow \beta) \equiv (\neg \alpha \vee \beta)$, eliminação da implicação.
\item $(\alpha \Leftrightarrow \beta) \equiv ((\alpha \Rightarrow \beta) \wedge (\beta \Rightarrow \alpha))$, eliminação da bicondicional.
\item $\neg(\alpha \wedge \beta) \equiv (\neg \alpha \vee \neg \beta)$, De Morgan.
\item $\neg(\alpha \vee \beta) \equiv (\neg \alpha \wedge \neg \beta)$, De Morgan.
\item $(\alpha \wedge (\beta \vee \gamma)) \equiv ((\alpha \wedge \beta) \vee (\alpha \wedge \gamma))$, distributividade.
\item $(\alpha \vee (\beta \wedge \gamma)) \equiv ((\alpha \vee \beta) \wedge (\alpha \vee \gamma))$, distributividade.
\end{itemize}
\subsection{Validade e satisfatibilidade}
Uma proposição é \textbf{valida} se for verdadeira em todos os modelos.\\
A validade está relacionada com a consequência pelo \textbf{teorema da dedução}:
\begin{center}
KB $\models \alpha$ é valida apenas se KB $\Rightarrow \alpha$ é valida.
\end{center}
Uma proposição é \textbf{satisfazível} se existirem modelos que a verifiquem, e \textbf{insatisfazivel} se não houverem modelos que a verifiquem.\\
$A \wedge \neg A$ é um exemplo de uma preposição instatisfazivel.\\[0.2cm]
A insatisfabilidade pode ser relacionado com a consequência (pelo teorema acima) da seguinte forma:
\begin{center}
KB $\models \alpha$ é valida apenas se KB $\wedge \neg \alpha$ for insatisfazivel.
\end{center}
Um exemplo da utilização da utilidade deste caso do teorema é a prova por redução ao absurdo.
\section{Exemplo: Mundo do Wumpus}
O mundo do Wumpus é um exemplo de um puzzle que pode ser resolvível com um agente.\\
É caraterizado por um mapa em grelha com diversas armadilhas, um inimigo, e um tesouro que se pretende obter.\\
O \textbf{ambiente} verifica que:
\begin{itemize}
\item Casas adjacentes ao Wumpus são mal-cheirosas.
\item Casas adjacentes a um poço são ventosas.
\item Brilho só se ouro está na mesma casa.
\item Disparo mata Wumpus se estiver em frente.
\item Disparar gasta única seta.
\item Agarrar apanha o ouro da casa.
\item Largar deixa o ouro na mesma casa.
\end{itemize}
O agente tem os seguintes \textbf{sensores}:
\begin{itemize}
\item Brisa, brilho, cheiro, grito e batida.
\end{itemize}
E os seguintes \textbf{atuadores}:
\begin{itemize}
\item Rodar esquerda, rodar direita, avançar, agarrar, largar, disparar, sair.
\end{itemize}
Uma medida de desempenho poderá seguir os critérios:
\begin{itemize}
\item Sair com ouro: +1000 pontos
\item Morte: -1000 pontos
\item Passo: -1 pontos
\item Utilizar a seta: -10 pontos
\end{itemize}
Assim uma caraterização do mundo conclui que é:
\begin{itemize}
\item \textbf{Não observável} - Só se perceciona o próprio local.
\item \textbf{Determinístico} - Os resultados das mesmas ações são sempre idênticos.
\item \textbf{Não episódico} - Ações sequenciais.
\item \textbf{Estático} - O Wumpus e os poços não se movem.
\item \textbf{Discreto} - As ações são atómicas.
\item \textbf{Agente único} - Mais nada interage com o ambiente.
\end{itemize}
[Ilustrar mapa, Tikz?]\\[0.5cm]
Dão-se situações em que não existe nenhum caminho livre de risco, como o jogador se encontrar na posição (1,1) e existir um poço na posição (2,2). Qualquer movimento admite uma chance de erro.\\
Para os cenários desconhecidos estudam-se os modelos possíveis.
No mundo do Wumpus a base de conhecimento é uma agregação das regras de jogo ás observações já efetuadas.
\end{document}